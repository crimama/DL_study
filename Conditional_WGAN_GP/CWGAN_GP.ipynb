{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Input, Reshape\n",
    "from tensorflow.keras.layers import LeakyReLU, Activation\n",
    "from tensorflow.keras.layers import Cropping2D, ZeroPadding2D, UpSampling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import backend as k \n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.callbacks import Callback\n",
    "from tqdm import tqdm \n",
    "import gc\n",
    "\n",
    "from Build_model import Generator,Discriminator,Adversarial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.keras.datasets.mnist\n",
    "# dataset = tf.keras.datasets.fashion_mnist\n",
    "(train_images, _), (test_images, _) = dataset.load_data()\n",
    "\n",
    "# IMAGE_SHAPE = (128, 128, 3)\n",
    "IMAGE_SHAPE = (32, 32,1)\n",
    "\n",
    "def preprocess(images):\n",
    "    if images.shape[1:3] != IMAGE_SHAPE:\n",
    "        import cv2\n",
    "        def resize(image):\n",
    "            return cv2.resize(image, IMAGE_SHAPE[:2]) #28,28 -> 32,32\n",
    "        images = np.array([resize(image) for image in images])\n",
    "    # if len(images.shape)!=4:\n",
    "    #     images = np.stack((images,)*IMAGE_SHAPE[-1], axis=-1) #32,32 -> 32,32,3\n",
    "\n",
    "    images = images.astype(np.float32)\n",
    "    maxs = np.max(images)\n",
    "    mins = np.min(images)\n",
    "    images = (images - mins) / (maxs-mins)\n",
    "    images = images.reshape(-1,32,32,1)\n",
    "    return images\n",
    "\n",
    "train_images = preprocess(train_images)[:10000]\n",
    "test_images = preprocess(test_images)\n",
    "\n",
    "HALF_IMAGE_SHAPE = (IMAGE_SHAPE[0], IMAGE_SHAPE[1]//2, IMAGE_SHAPE[2])\n",
    "print(HALF_IMAGE_SHAPE)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LATENT_DIM = 128 \n",
    "IMAGE_SIZE = 32\n",
    "CLIP_VALUE = 0.01 \n",
    "N_CRITIC = 5 \n",
    "LR = 5e-5\n",
    "DECAY = 6e-8\n",
    "TRAIN_STEPS = 40000\n",
    "MODEL_NAME = 'CWGAN_GP'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 선언 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" loss 선언\"\"\"\n",
    "#sasserstein_loss\n",
    "def wasserstein_loss(y_label,y_pred):\n",
    "    return -k.mean(y_label*y_pred)\n",
    "\n",
    "\"\"\"\n",
    "모델 선언\n",
    "\"\"\"\n",
    "noise_input = Input(LATENT_DIM)\n",
    "image_input = Input(shape=(32,32,1))\n",
    "condition_input = Input(shape=(32,16,1))\n",
    "\n",
    "#식별자 \n",
    "d_model = Discriminator(image_input,condition_input).build_dicriminator()\n",
    "d_optimizer = RMSprop(learning_rate=LR, decay = DECAY)\n",
    "d_model.compile(loss = wasserstein_loss,\n",
    "                optimizer = d_optimizer,\n",
    "                metrics = ['accuracy'])\n",
    "d_model.trainable=False\n",
    "\n",
    "#생성자\n",
    "g_model = Generator(noise_input,condition_input,32).build_generator()\n",
    "g_optimizer = RMSprop(learning_rate=LR*0.5, decay = DECAY*0.5)\n",
    "\n",
    "#대립 모델 \n",
    "adversarial = Adversarial(g_model,d_model,noise_input,condition_input).build_adversarial()\n",
    "adversarial.compile(loss = wasserstein_loss,\n",
    "                    optimizer = g_optimizer,\n",
    "                    metrics = ['accuracy'])\n",
    "models = (g_model,d_model,adversarial)\n",
    "params = (BATCH_SIZE,LATENT_DIM,N_CRITIC,CLIP_VALUE,TRAIN_STEPS,MODEL_NAME)\n",
    "train(models,train_images,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(batch_size, conditions, real_images, fake_images):\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            pred = discriminator([conditions, interpolated], training=True)\n",
    "\n",
    "        grads = gp_tape.gradient(pred, [conditions, interpolated])[1]\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "\n",
    "def train(models,x_train,params):\n",
    "    generator, discriminator, adversarial = models\n",
    "\n",
    "    (batch_size, latent_size, n_critic,clip_value, train_steps, model_name) = params\n",
    "\n",
    "    save_interval = 250 #500단계 마다 생성기 이미지 저장 \n",
    "\n",
    "    noise_input = np.random.uniform(-1,1,size=[16,latent_size]) #훈련 동안 생성기 변화 확인 \n",
    "    train_size = x_train.shape[0]\n",
    "    image_size = x_train.shape[1]\n",
    "\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "\n",
    "    for i in tqdm(range(train_steps)):\n",
    "        loss = 0 \n",
    "        acc = 0 \n",
    "        for _ in range(n_critic): #판별기 5회 학습 \n",
    "            \"\"\"\n",
    "            데이터 생성 \n",
    "            \"\"\"\n",
    "            #진짜 데이터 \n",
    "            rand_indexes = np.random.randint(0,train_size,size=batch_size)\n",
    "            real_images = x_train[rand_indexes]\n",
    "            #가짜 데이터 \n",
    "            noise = np.random.uniform(-1,1,size=[batch_size,latent_size])\n",
    "            condition = train_images[rand_indexes][:batch_size,:,:int(image_size/2),:]\n",
    "            fake_images = generator.predict([noise,condition])\n",
    "            \n",
    "            \"\"\"\n",
    "            학습 \n",
    "            \"\"\"\n",
    "            #학습 - 진짜 데이터와 가짜 데이터 나눠서 학습 함 \n",
    "            real_loss, real_acc = \\\n",
    "                discriminator.train_on_batch([real_images,condition],real_labels)\n",
    "            fake_loss, fake_acc = \\\n",
    "                discriminator.train_on_batch([fake_images,condition],-real_labels)\n",
    "            #가짜 데이터 라벨을 -1로 넣음 \n",
    "\n",
    "            \"\"\"\n",
    "            학습 후 평가 \n",
    "            \"\"\"\n",
    "            loss += 0.5 * (real_loss + fake_loss) #loss 두개 평균 \n",
    "            acc += 0.5 * (real_acc + fake_acc) #acc 평균 \n",
    "            \n",
    "            \"\"\"\n",
    "            Weights Clipping \n",
    "            \"\"\"\n",
    "            #weight clip -> 립시츠 상수 만족시키기 위해서\n",
    "            #각 layer의 weight를 출력한 뒤 cilp 후 다시 세팅 \n",
    "            for layer in discriminator.layers:\n",
    "                weights = layer.get_weights()\n",
    "                weights = [np.clip(weight,-clip_value,clip_value) for weight in weights]\n",
    "                layer.set_weights(weights)\n",
    "        loss /= n_critic #판별기 5번 학습 시킨 거 평균 냄 \n",
    "        acc /= n_critic \n",
    "        log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n",
    "\n",
    "        \"\"\"\n",
    "        생성기 학습 \n",
    "        \"\"\"\n",
    "        noise = np.random.uniform(-1,1,size=[batch_size,latent_size])\n",
    "        loss, acc = adversarial.train_on_batch([noise,condition], real_labels)\n",
    "        log = \"%s [adversarial loss :%f, acc :%f\" % (log,loss,acc)\n",
    "        \n",
    "        if (i+1) % save_interval == 0 : \n",
    "            print(log)\n",
    "            plot_images(generator,noise_input,x_train[:16])\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(generator,noise_input,image_input):\n",
    "    condition = image_input[:,:,:16]\n",
    "    fake_images = generator.predict([noise_input,condition])\n",
    "    fake_images = fake_images[:,:,16:]\n",
    "    concat_images = np.concatenate([condition,fake_images],axis=2)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(7):\n",
    "        plt.subplot(1,7,i+1)\n",
    "        plt.imshow(concat_images[i],cmap='gray')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39905bc9c811c4a98ed98e9351e06a50eb41a2835050207f19a713eb00ecce7a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('basement')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
