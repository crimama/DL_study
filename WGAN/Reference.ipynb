{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains WGAN on MNIST using Keras\n",
    "\n",
    "Trains a GAN using Wassertein loss. Similar to DCGAN except for\n",
    "linear activation in output and use of n_critic training per\n",
    "adversarial training. Discriminator weights are clipped as a\n",
    "requirement of Lipschitz constraint.\n",
    "\n",
    "[1] Radford, Alec, Luke Metz, and Soumith Chintala.\n",
    "\"Unsupervised representation learning with deep convolutional\n",
    "generative adversarial networks.\" arXiv preprint arXiv:1511.06434 (2015).\n",
    "\n",
    "[2] Arjovsky, Martin, Soumith Chintala, and Léon Bottou.\n",
    "\"Wasserstein GAN.\" arXiv preprint arXiv:1701.07875 (2017).\n",
    "'''\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from lib import gan\n",
    "\n",
    "def train(models, x_train, params):\n",
    "\n",
    "    generator, discriminator, adversarial = models\n",
    "    (batch_size, latent_size, n_critic,clip_value, train_steps, model_name) = params\n",
    "    save_interval = 500\n",
    "\n",
    "    noise_input = np.random.uniform(-1.0,1.0, size=[16, latent_size])\n",
    "    train_size = x_train.shape[0]\n",
    "\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "\n",
    "    for i in range(train_steps):\n",
    "        loss = 0\n",
    "        acc = 0\n",
    "        for _ in range(n_critic):\n",
    "            #진짜 이미지\n",
    "            rand_indexes = np.random.randint(0,train_size, size=batch_size)\n",
    "            real_images = x_train[rand_indexes]\n",
    "            #가짜 이미지 \n",
    "            noise = np.random.uniform(-1.0,1.0,size=[batch_size, latent_size])\n",
    "            fake_images = generator.predict(noise)\n",
    "\n",
    "\n",
    "            real_loss, real_acc = \\\n",
    "                discriminator.train_on_batch(real_images,\n",
    "                                             real_labels)\n",
    "            fake_loss, fake_acc = \\\n",
    "                discriminator.train_on_batch(fake_images,\n",
    "                                             -real_labels) #가짜 이미지 이지만 1이라고 속임\n",
    "\n",
    "            # accumulate average loss and accuracy\n",
    "            loss += 0.5 * (real_loss + fake_loss)\n",
    "            acc += 0.5 * (real_acc + fake_acc)\n",
    "\n",
    "            # clip discriminator weights to satisfy Lipschitz constraint\n",
    "            for layer in discriminator.layers:\n",
    "                weights = layer.get_weights()\n",
    "                weights = [np.clip(weight,-clip_value,clip_value) for weight in weights]\n",
    "                layer.set_weights(weights)\n",
    "\n",
    "        loss /= n_critic\n",
    "        acc /= n_critic\n",
    "        log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n",
    "\n",
    " \n",
    "        noise = np.random.uniform(-1.0,1.0,size=[batch_size, latent_size])\n",
    "    \n",
    "        loss, acc = adversarial.train_on_batch(noise, real_labels)\n",
    "        log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n",
    "        print(log)\n",
    "        if (i + 1) % save_interval == 0:\n",
    "            # plot generator images on a periodic basis\n",
    "            gan.plot_images(generator,\n",
    "                            noise_input=noise_input,\n",
    "                            show=False,\n",
    "                            step=(i + 1),\n",
    "                            model_name=model_name)\n",
    "\n",
    "    # save the model after training the generator\n",
    "    # the trained generator can be reloaded \n",
    "    # for future MNIST digit generation\n",
    "    generator.save(model_name + \".h5\")\n",
    "\n",
    "\n",
    "def wasserstein_loss(y_label, y_pred):\n",
    "    return -K.mean(y_label * y_pred)\n",
    "\n",
    "\n",
    "def build_and_train_models():\n",
    "    \"\"\"Load the dataset, build WGAN discriminator,\n",
    "    generator, and adversarial models.\n",
    "    Call the WGAN train routine.\n",
    "    \"\"\"\n",
    "    # load MNIST dataset\n",
    "    (x_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # reshape data for CNN as (28, 28, 1) and normalize\n",
    "    image_size = x_train.shape[1]\n",
    "    x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
    "    x_train = x_train.astype('float32') / 255\n",
    "\n",
    "    model_name = \"wgan_mnist\"\n",
    "    # network parameters\n",
    "    # the latent or z vector is 100-dim\n",
    "    latent_size = 100\n",
    "    # hyper parameters from WGAN paper [2]\n",
    "    n_critic = 5\n",
    "    clip_value = 0.01\n",
    "    batch_size = 64\n",
    "    lr = 5e-5\n",
    "    train_steps = 40000\n",
    "    input_shape = (image_size, image_size, 1)\n",
    "\n",
    "    # build discriminator model\n",
    "    inputs = Input(shape=input_shape, name='discriminator_input')\n",
    "    # WGAN uses linear activation in paper [2]\n",
    "    discriminator = gan.discriminator(inputs, activation='linear')\n",
    "    optimizer = RMSprop(lr=lr)\n",
    "    # WGAN discriminator uses wassertein loss\n",
    "    discriminator.compile(loss=wasserstein_loss,\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "    discriminator.summary()\n",
    "\n",
    "    # build generator model\n",
    "    input_shape = (latent_size, )\n",
    "    inputs = Input(shape=input_shape, name='z_input')\n",
    "    generator = gan.generator(inputs, image_size)\n",
    "    generator.summary()\n",
    "\n",
    "    # build adversarial model = generator + discriminator\n",
    "    # freeze the weights of discriminator during adversarial training\n",
    "    discriminator.trainable = False\n",
    "    adversarial = Model(inputs,\n",
    "                        discriminator(generator(inputs)),\n",
    "                        name=model_name)\n",
    "    adversarial.compile(loss=wasserstein_loss,\n",
    "                        optimizer=optimizer,\n",
    "                        metrics=['accuracy'])\n",
    "    adversarial.summary()\n",
    "\n",
    "    # train discriminator and adversarial networks\n",
    "    models = (generator, discriminator, adversarial)\n",
    "    params = (batch_size,\n",
    "              latent_size,\n",
    "              n_critic,\n",
    "              clip_value,\n",
    "              train_steps,\n",
    "              model_name)\n",
    "    train(models, x_train, params)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    help_ = \"Load generator h5 model with trained weights\"\n",
    "    parser.add_argument(\"-g\", \"--generator\", help=help_)\n",
    "    args = parser.parse_args()\n",
    "    if args.generator:\n",
    "        generator = load_model(args.generator)\n",
    "        gan.test_generator(generator)\n",
    "    else:\n",
    "        build_and_train_models()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
